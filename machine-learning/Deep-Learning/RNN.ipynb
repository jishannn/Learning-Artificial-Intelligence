{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**RNN - Recurrent Neural Network**"
      ],
      "metadata": {
        "id": "EXdWflvnrhbD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An RNN (Recurrent Neural Network) is a type of neural network that works great for sequential data — stuff like text, time-series, or anything where order matters.\n",
        "\n",
        "In a regular neural net, we look at inputs all at once. But an RNN looks at things one step at a time, remembering things along the way using its hidden state — like a little memory."
      ],
      "metadata": {
        "id": "hJyQgKcUvTnf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rgz8OGExrMww"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import one_hot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Character Preprocessing**"
      ],
      "metadata": {
        "id": "KeMyCZYMr_cF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Character mapping\n",
        "chars = sorted(list(set(\"hello\")))\n",
        "char2idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx2char = {i: ch for ch, i in char2idx.items()}\n",
        "vocab_size = len(chars)\n",
        "\n",
        "# Convert sequence to indices\n",
        "seq = \"hello\"\n",
        "input_seq = [char2idx[ch] for ch in seq[:-1]]\n",
        "target_seq = [char2idx[ch] for ch in seq[1:]]\n",
        "\n",
        "# Convert to tensors\n",
        "input_tensor = one_hot(torch.tensor(input_seq), num_classes=vocab_size).float().unsqueeze(0)\n",
        "target_tensor = torch.tensor(target_seq)"
      ],
      "metadata": {
        "id": "z5lRI98mr1qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN Model**\n"
      ],
      "metadata": {
        "id": "rc3v3ZVstDjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleRNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size):\n",
        "    super(SimpleRNN, self).__init__()\n",
        "    self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "  def forward(self, x, h0):\n",
        "    out, hn = self.rnn(x, h0)\n",
        "    out = self.fc(out)\n",
        "    return out, hn\n",
        "\n",
        "hidden_size = 16\n",
        "model = SimpleRNN(vocab_size, hidden_size, vocab_size)"
      ],
      "metadata": {
        "id": "4aY_czoQtBMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train the Model**"
      ],
      "metadata": {
        "id": "m9_aTCzAtyGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  h0 = torch.zeros(1, 1, hidden_size)\n",
        "  output, hn = model(input_tensor, h0)\n",
        "\n",
        "  loss = criterion(output.view(-1, vocab_size), target_tensor)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch+1) % 20 == 0:\n",
        "    pred = output.argmax(dim=2).squeeze().tolist()\n",
        "    pred_chars = [idx2char[i] for i in pred]\n",
        "    print(f\"Epoch {epoch+1}: Loss= {loss.item():.4f}, Prediction: {''.join(pred_chars)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvKcGlKntwTb",
        "outputId": "f78891c2-f711-4396-a60c-c868bbf21db6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20: Loss= 0.3261, Prediction: ello\n",
            "Epoch 40: Loss= 0.0292, Prediction: ello\n",
            "Epoch 60: Loss= 0.0095, Prediction: ello\n",
            "Epoch 80: Loss= 0.0058, Prediction: ello\n",
            "Epoch 100: Loss= 0.0043, Prediction: ello\n",
            "Epoch 120: Loss= 0.0033, Prediction: ello\n",
            "Epoch 140: Loss= 0.0027, Prediction: ello\n",
            "Epoch 160: Loss= 0.0022, Prediction: ello\n",
            "Epoch 180: Loss= 0.0019, Prediction: ello\n",
            "Epoch 200: Loss= 0.0016, Prediction: ello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the RNN-based Name Predictor**"
      ],
      "metadata": {
        "id": "qBlDhPdPwWM5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import one_hot\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "FwFnCJVQu6Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The baby name dataset\n",
        "names = [\"alice\", \"alvin\", \"alex\", \"albert\", \"alena\"]\n",
        "names = [name + \"#\" for name in names]\n",
        "\n",
        "# Create char dictionary\n",
        "chars = sorted(list(set(\"\".join(names))))\n",
        "character2idx = {ch: i for i, ch in enumerate(chars)}\n",
        "idx2character = {i: ch for ch, i in character2idx.items()}\n",
        "vocab_size = len(chars)"
      ],
      "metadata": {
        "id": "dtX3eYMcxIjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Custom Dataset for Character Sequences**"
      ],
      "metadata": {
        "id": "oPFSivs7xWpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NameDataset(Dataset):\n",
        "  def __init__(self, names, seq_len = 4):\n",
        "    self.data = []\n",
        "    for name in names:\n",
        "      for i in range(1, len(name)):\n",
        "        input_seq = name[:i]\n",
        "        target_seq = name[1:i+1]\n",
        "        self.data.append((input_seq, target_seq))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    inp, tgt = self.data[idx]\n",
        "    inp_ids = [character2idx[ch] for ch in inp]\n",
        "    tgt_ids = [character2idx[ch] for ch in tgt]\n",
        "\n",
        "    input_tensor = one_hot(torch.tensor(inp_ids), num_classes=vocab_size).float()\n",
        "    target_tensor = torch.tensor(tgt_ids)\n",
        "    return input_tensor, target_tensor\n",
        "\n",
        "dataset = NameDataset(names)\n",
        "loader = DataLoader(dataset, batch_size=1, shuffle=True)"
      ],
      "metadata": {
        "id": "g6hK244cxMJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RNN Model**"
      ],
      "metadata": {
        "id": "Z4qFL5tgyvcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NameRNN(nn.Module):\n",
        "  def __init__(self, vocab_size, hidden_size):\n",
        "    super(NameRNN, self).__init__()\n",
        "    self.rnn = nn.RNN(vocab_size, hidden_size, batch_first=True)\n",
        "    self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "  def forward(self, x, h0=None):\n",
        "    out, h = self.rnn(x, h0)\n",
        "    out = self.fc(out)\n",
        "    return out, h\n",
        "\n",
        "model = NameRNN(vocab_size=vocab_size, hidden_size=32)"
      ],
      "metadata": {
        "id": "VP7S_GkIyjLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the Model**"
      ],
      "metadata": {
        "id": "vxLv_2eTzWQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(300):\n",
        "  total_loss = 0\n",
        "  for inputs, targets in loader:\n",
        "    h0 =  torch.zeros(1, 1, 32)\n",
        "    output, _ = model(inputs, h0)\n",
        "\n",
        "    loss = criterion(output.view(-1, vocab_size), targets.view(-1))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  if (epoch + 1) % 50 == 0:\n",
        "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jaKYOlAzUaB",
        "outputId": "7f787a4e-0ff0-40e2-e614-19c353cdd676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 50 Loss: 11.2250\n",
            "Epoch 100 Loss: 11.9426\n",
            "Epoch 150 Loss: 10.9508\n",
            "Epoch 200 Loss: 10.2223\n",
            "Epoch 250 Loss: 10.4068\n",
            "Epoch 300 Loss: 10.4851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction Function — **Autocomplete**!"
      ],
      "metadata": {
        "id": "-EaTaFhV3skz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(start, max_len=10):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        chars_input = [character2idx[ch] for ch in start]\n",
        "        input_tensor = one_hot(torch.tensor(chars_input), num_classes=vocab_size).float().unsqueeze(0)\n",
        "        h = None\n",
        "        result = start\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            output, h = model(input_tensor, h)\n",
        "            pred_id = output[0, -1].argmax().item()\n",
        "            pred_char = idx2character[pred_id]\n",
        "\n",
        "            if pred_char == \"#\":\n",
        "                break\n",
        "\n",
        "            result += pred_char\n",
        "\n",
        "            next_input = one_hot(torch.tensor([[pred_id]]), num_classes=vocab_size).float()\n",
        "            input_tensor = next_input\n",
        "\n",
        "        return result\n"
      ],
      "metadata": {
        "id": "Jl3TU9ua0M0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict(\"al\"))\n",
        "print(predict(\"alb\"))\n",
        "print(predict(\"ale\"))\n",
        "print(predict(\"ali\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-1yka_W1fJR",
        "outputId": "9aef5c84-9dd3-43dd-bfc4-9d8be84077f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alena\n",
            "albert\n",
            "alena\n",
            "alice\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fY7DG2LD1i_P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}